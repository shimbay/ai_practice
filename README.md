## flash_attn

```
python3 -m attention.flash_attn
```

## moe

Vectorized implementation for LLM MOE Expert Parallelism.

```
python3 -m moe.main
```

## torch backend

Out-of-tree custom torch backend, implement device / stream / memory management.

```
./torch/test_openreg.sh
```
