## flash_attn

```
python3 -m attention.flash_attn
```

## moe

Vectorized implementation for LLM MOE Expert Parallelism.

```
python3 -m moe.main
```
